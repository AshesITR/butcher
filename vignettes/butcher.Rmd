---
title: "butcher"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{butcher}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(butcher)
library(parsnip)
```

One of the beauties of working with `R` is the ease with which you can implement intricate models and make challenging data analysis pipelines seem almost trivial. Take, for example, the `parsnip` package; with the installation of a few associated libraries and a few lines of code, you can fit something as complex as a boosted tree:  

```{r, warning = F, message = F, eval = F}
library(rpart)

fitted_model <- boost_tree(trees = 15) %>%
  set_engine("C5.0") %>%
  fit(as.factor(am) ~ disp + hp, data = mtcars)
```

Or, let’s say you’re working on petabytes of data, in which the data is distributed across clusters of thousands of nodes. Just switch out the engine: 

```{r, warning = F, message = F, eval = F}
library(sparklyr)

sc <- spark_connect(master = "local")

mtcars_tbls <- sdf_copy_to(sc, mtcars[, c("am", "disp", "hp")], overwrite = TRUE)

fitted_model <- boost_tree(trees = 15) %>%
  set_engine("spark") %>%
  fit(am ~ disp + hp, data = mtcars_tbls)
```

Yet, while our code might appear compact, the underlying fitted result is not. Currently, `parsnip` works as a wrapper for many modeling packages built off of base `R`, and as a result, its inherits the same properties as that of objects that arise from these modeling packages. Take, for example, the popular `lm` function we often rely on from the base `stats`. Whether you leverage `parsnip` or not, you will get the same result:

```{r, warning = F, message = F}
parsnip_lm <- linear_reg() %>% 
  set_engine("lm") %>% 
  fit(mpg ~ ., data = mtcars) 
parsnip_lm
str(parsnip_lm$fit, max.level = 1, list.len = 10)
```

Using base R:

```{r, warning = F, message = F}
old_lm <- lm(mpg ~ ., data = mtcars) 
old_lm
str(old_lm, max.level = 1, list.len = 10)
```

Given our familiarity with base `R`, let's say we take we take the `old_lm` approach in building our in-house modeling pipeline. Such a pipeline might entail wrapping our `lm` model in other function. But in doing so, we might end up carrying a lot of junk. For example: 

```{r, warning = F, message = F}
in_house_model <- function() {
  some_junk_in_the_environment <- matrix(1:1e6, ncol = 10) # we didn't know about
  lm(mpg ~ ., data = mtcars) 
}
```

This `lm` that exists in our pipeline is: 

```{r, warning = F, message = F}
lobstr::obj_size(in_house_model())
```

When its really just the same as our `old_lm`, which is only: 

```{r, warning = F, message = F}
lobstr::obj_size(old_lm)
```

Obviously we don't want to end up saving this new `in_house_model()` on disk, when we could have something like `old_lm` that takes up much less memory. So what the heck is going on here? We can examine this with the `butcher` package: 

```{r, warning = F, message = F}
big_lm <- in_house_model()
butcher::weigh(big_lm, threshold = 0, units = "MB")
```

The problem here is in the `terms` component of `big_lm`. Because of how `lm` is implemented in the base `stats` package, the environment in which the `lm` model was created was carried along in the model output. We can see this with the `env_print` function from `rlang`:  

```{r, warning = F, message = F}
library(rlang)
rlang::env_print(big_lm$terms)
```

To avoid carrying this junk in our production pipeline, whether it be associated with an `lm` model (or something more complex), we can leverage the `axe_env` within `butcher`. In other words, 

```{r, warning = F, message = F}
cleaned_lm <- butcher::axe_env(big_lm)
```

Comparing it against our `old_lm`, we'll find:

```{r, warning = F, message = F}
butcher::weigh(cleaned_lm, threshold = 0, units = "MB")
```

...it now takes the same memory on disk as `old_lm`:

```{r, warning = F, message = F}
butcher::weigh(old_lm, threshold = 0, units = "MB")
```

Axing the environment, however, is not the only functionality of `butcher`. This package provides six S3 generics that include: 

- `axe_call`: Remove the call object. 
- `axe_ctrl`: Remove the controls fixed for training.
- `axe_data`: Remove the original data.
- `axe_env`: Replace untidy environments. 
- `axe_fitted`: Replace fitted values.
- `axe_misc`: Replace intermediate pipelines saved from training.

In our case here with `lm`, if we are only interested in prediction as the end product of our modeling pipeline, we could free up a lot of memory if we axe all the fat that the `lm` object carries, i.e., the call, its fitted values, the data---all things saved for characterizing the model. If we are comfortable with axing everything we can, we can simply run `butcher` with the peace of mind that `predict` still works.

```{r, warning = F, message = F}
butchered_lm <- butcher::butcher(big_lm)
predict(butchered_lm, mtcars[, 2:11])
```

Alternatively, we can pick and choose specific axe functions: 

```{r, warning = F, message = F}
butchered_lm <- big_lm %>%
  butcher::axe_env() %>% 
  butcher::axe_fitted()
predict(butchered_lm, mtcars[, 2:11])
```

